{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQT862KlVWNTyD8R15t+Cr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BSniegowski/ML-uni_course/blob/main/project/mdd_eeg_diagnosis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "ChHYQdw13-eX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEKHKQzxdcph",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download and unzip data\n",
        "!wget https://figshare.com/ndownloader/articles/4244171/versions/2\n",
        "!unzip 2\n",
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load files\n",
        "import os\n",
        "import mne\n",
        "\n",
        "mne.set_log_level('ERROR')\n",
        "\n",
        "\n",
        "raws = []\n",
        "for file in os.scandir('.'):\n",
        "  _, ext = os.path.splitext(file.path)\n",
        "  if ext == \".edf\":\n",
        "    raws.append(mne.io.read_raw_edf(file.path))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5mpDrHr8flQM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset class\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# ignoring timestamps - treating data as sequences\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, raws, transform=None, segment_length=60):\n",
        "    self.segment_length = segment_length\n",
        "    self.data = []\n",
        "    self.labels = []\n",
        "    for raw in raws:\n",
        "      label = 1 if \"MDD\" in raw.filenames[0] else 0\n",
        "      data = torch.squeeze(torch.as_tensor(raw.load_data()[:20,:][0]))\n",
        "      length_seconds = data.size()[1]/256\n",
        "      i=0\n",
        "      while (i+1)*segment_length < length_seconds:\n",
        "        x = data[:,i*segment_length*256:(i+1)*segment_length*256]\n",
        "        self.data.append(x)\n",
        "        self.labels.append(label)\n",
        "        i += 1\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    X, y = self.data[idx], self.labels[idx]\n",
        "    if self.transform is not None:\n",
        "      X = self.transform(X)\n",
        "    X = torch.as_tensor(X[None, ...])\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "XuQsaV59gX7o",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DataLoaders\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "\n",
        "dataset = CustomDataset(raws, transform=torch.nn.functional.normalize, segment_length=2)\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [0.8, 0.2])\n",
        "train_batch_size = 4\n",
        "test_batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EHoz7h39jwT0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title show results\n",
        "def show_results(logs):\n",
        "  f, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
        "  ax[0].plot(logs['train_accuracy'], color='b', linestyle='--', label='train')\n",
        "  ax[0].plot(logs['test_accuracy'], color='g', label='test')\n",
        "  ax[0].set_xlabel('epochs')\n",
        "  ax[0].set_ylabel('accuracy')\n",
        "  ax[0].legend()\n",
        "\n",
        "  ax[1].plot(logs['train_loss'], color='b', linestyle='--', label='train')\n",
        "  ax[1].plot(logs['test_loss'], color='g', label='test')\n",
        "  ax[1].set_xlabel('epochs')\n",
        "  ax[1].set_ylabel('loss')\n",
        "  ax[1].legend()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5Y5wmjHW_xKG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MyModel\n",
        "from torch import nn\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, kernel_size=5, stride=3, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1),\n",
        "        nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1),\n",
        "    )\n",
        "    self.adaptivepool = nn.AdaptiveAvgPool2d((20, 64))\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(32*20*64, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.adaptivepool(x)\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "iZPUlmDOAurH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train loop\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bad_data = None\n",
        "\n",
        "def train(model, optimizer, loss_fn, learning_rate, n_epochs, logs, scheduler):\n",
        "  model.train()\n",
        "\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "  correct, numel = 0, 0\n",
        "\n",
        "  for i in range(n_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for x, y in train_loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      bad_data = x\n",
        "      output = model(x)\n",
        "      output = torch.squeeze(output)\n",
        "      y_pred = output > 0.5\n",
        "      correct += torch.sum(y_pred == y).item()\n",
        "      numel += train_loader.batch_size\n",
        "      y = y.double()\n",
        "      loss = loss_fn(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if scheduler is not None:\n",
        "      scheduler.step(loss)\n",
        "      print(optimizer.param_groups[0]['lr'])\n",
        "    logs['train_loss'].append(loss.item())\n",
        "    logs['train_accuracy'].append(correct / numel)\n",
        "    correct, numel = 0, 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x_test, y_test in test_loader:\n",
        "        x_test = x_test.to(device)\n",
        "        y_test = y_test.to(device)\n",
        "        bad_data = x_test\n",
        "        output = model(x_test)\n",
        "        output = torch.squeeze(output)\n",
        "        y_pred = output > 0.5\n",
        "        correct += torch.sum(y_pred == y_test).item()\n",
        "        numel += test_loader.batch_size\n",
        "      y_test = y_test.double()\n",
        "      loss = loss_fn(output, y_test)\n",
        "\n",
        "    logs['test_loss'].append(loss.item())\n",
        "    logs['test_accuracy'].append(correct / numel)\n",
        "    correct, numel = 0, 0\n",
        "    show_results(logs)\n",
        "    plt.pause(1e-10)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ikL-Tq0sIjKm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train MyModel\n",
        "model = MyModel()\n",
        "model.double()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device: \", device)\n",
        "model.to(device)\n",
        "loss_fn = nn.BCELoss()\n",
        "LR = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "\n",
        "logs = {'train_loss': [], 'test_loss': [], 'train_accuracy': [], 'test_accuracy': []}\n",
        "train(model=model, optimizer=optimizer, loss_fn=loss_fn, learning_rate=LR, n_epochs=200, logs=logs)"
      ],
      "metadata": {
        "id": "AzXcFZTqBDo1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import contains\n",
        "#@title GRU_model\n",
        "class GRU_model(nn.Module):\n",
        "  def __init__(self, hidden_size, segment_length):\n",
        "    super(GRU_model, self).__init__()\n",
        "    self.segment_length = segment_length\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, kernel_size=5, stride=3, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1),\n",
        "        nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1),\n",
        "        nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.adaptivepool = nn.AdaptiveAvgPool2d((20, 256*segment_length//3))\n",
        "    input_size = 20 # our data comes from 20 electrodes\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "    self.classifier = nn.Sequential(\n",
        "    #     nn.Dropout(p=0.5),\n",
        "        nn.Linear(hidden_size, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.adaptivepool(x)\n",
        "    x = torch.squeeze(x) # reduce channel dimension = 1\n",
        "    # reshape to (batch_size, sequence_length, input_size)\n",
        "    x = torch.reshape(x, (x.size()[0], x.size()[2], -1))\n",
        "    x, hidden = self.rnn(x)\n",
        "    x = x[:,-1] # take only last output\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "hidden_size = 32\n",
        "segment_length = dataset.segment_length\n",
        "gru_model = GRU_model(hidden_size, segment_length)\n",
        "gru_model.double()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device: \", device)\n",
        "gru_model.to(device)\n",
        "loss_fn = nn.BCELoss()\n",
        "LR = 0.001\n",
        "n_epochs = 100\n",
        "optimizer = torch.optim.SGD(gru_model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "\n",
        "logs2 = {'train_loss': [], 'test_loss': [], 'train_accuracy': [], 'test_accuracy': []}\n",
        "train(gru_model, optimizer, loss_fn, LR, n_epochs, logs2, scheduler)\n",
        "# bad_data = None\n",
        "# for x, y in train_loader:\n",
        "#   x = x.to(device)\n",
        "#   output = gru_model(x)\n",
        "#   if torch.sum(torch.isnan(output)) > 0:\n",
        "#     bad_data = x\n",
        "#     print(output)\n",
        "#     print(x.size())\n",
        "#     break\n",
        "#   print(output)\n",
        "#   break\n",
        "  # if torch.sum(torch.where((output > 1) | (output < 0), 1, 0)) > 0:\n",
        "  #   print(output) \n",
        "  #   break\n",
        "# output = torch.Tensor([0,2,1,-1,3])\n",
        "# x = torch.where((output > 1) | (output < 0), 1, 0)\n",
        "# print(x)"
      ],
      "metadata": {
        "id": "_yLo2rwX4SKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title save model architecture and performance\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp = datetime.now()\n",
        "test_acc = max(logs['test_accuracy']) * 100\n",
        "test_loss = min(logs['test_loss'])\n",
        "train_acc = max(logs['train_accuracy']) * 100\n",
        "train_loss = min(logs['train_loss'])\n",
        "!echo \"timestamp: $timestamp, test acc: $test_acc, test loss: $test_loss\" >> ./performance_history.txt\n",
        "!echo \"train acc: $train_acc, train loss: $train_loss\" >> ./performance_history.txt\n",
        "!echo \"$model.__dict__['_modules']\" >> ./performance_history.txt\n",
        "!echo \"$optimizer\" >> ./performance_history.txt\n",
        "!echo \"train batch: $train_batch_size, test batch: $test_batch_size\" >> ./performance_history.txt\n",
        "!echo \"$logs\" >> ./performance_history.txt\n",
        "!echo \"\" >> ./performance_history.txt\n",
        "!echo \"\" >> ./performance_history.txt"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MhzlLnP2WVTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}